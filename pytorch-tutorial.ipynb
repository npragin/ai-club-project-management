{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67ce0a73",
   "metadata": {},
   "source": [
    "# PyTorch Tutorial\n",
    "\n",
    "Author: Kellen Sullivan\n",
    "\n",
    "This is an introductory tutorial for the deep learning library PyTorch. PyTorch gives professional developers the tools to create and train their own custom neural networks, and is the most commonly used deep learning framework in research and academia.\n",
    "\n",
    "In this tutorial, you will be taught the fundamentals of PyTorch, through building your own neural network to classify hand-written digits. For this task, you will use the MNIST dataset, which is a collection of thousands of hand written digits with corresponding lables. Below is a sample of 4 hand-written digits from the dataset and their corresponding labels.\n",
    "\n",
    "\n",
    "![MNISTDataSetExample](https://media.geeksforgeeks.org/wp-content/uploads/20240430155943/download-(39).png)\n",
    "\n",
    "\n",
    "\n",
    "While you work through this tutorial and its exercises, its highly encouraged to check out the provided lecture videos created by math youtuber 3Blue1Brown. He explains the math behind the deep learning concepts this tutorial will breifly introduce, and his tutorials reference the exact same neural network that you will be building! His lessons are available to watch or read for free with the following link: [3Blue1Brown Neural Networks Lectures](https://www.3blue1brown.com/topics/neural-networks)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97513d30",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "To get started using PyTorch, you first have to install it! To do so, open a new terminal and run the following command:\n",
    "\n",
    "- If you are on Windows/Mac: `pip3 install torch torchvision`\n",
    "- If you are on Linux: `pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cpu`\n",
    "\n",
    "Note that these commands will use your CPU as the compute platform. If you have an NVIDIA GPU, you can install PyTorch with CUDA as the compute platform to greatly speed up training. Check out the official installation guide to learn more: https://pytorch.org/get-started/locally/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90390ff6",
   "metadata": {},
   "source": [
    "You can confirm PyTorch was successfully installed by importing the package and printing out its version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20f9b198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fdef34",
   "metadata": {},
   "source": [
    "## Tensors\n",
    "\n",
    "A tensor is an array or matrix like datastructure, similar to a NumPy array, but with extra capabalities that make it ideal for deep learning. Tensors may only contain numerical values, and are homogeneous meaning all elements in a tensor must be the same datatype."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ba4f3d",
   "metadata": {},
   "source": [
    "### Initializing a Tensor\n",
    "\n",
    "Pytorch provides many ways to intialize a new tensor. ADD HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4eaf1f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor from python list:\n",
      "tensor([1, 2, 3])\n",
      "\n",
      "Tensor from numpy array:\n",
      "tensor([[1, 2],\n",
      "        [3, 4]], dtype=torch.int32)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# from a python list\n",
    "t1 = torch.tensor([1,2,3])\n",
    "\n",
    "# from a numpy array\n",
    "np_arr = np.array([[1,2], [3,4]])\n",
    "t2 = torch.from_numpy(np_arr)\n",
    "\n",
    "print(f\"Tensor from python list:\\n{t1}\\n\")\n",
    "print(f\"Tensor from numpy array:\\n{t2}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f056b7d8",
   "metadata": {},
   "source": [
    "You can also initialize a tensor using an existing tensor. The new tensor will have the same shape and datatype as the existing tensor, unless explicitly overwritten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac274fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor from t2 with all ones:\n",
      "tensor([[1, 1],\n",
      "        [1, 1]], dtype=torch.int32)\n",
      "\n",
      "Tensor from t2 with all zeros:\n",
      "tensor([[0, 0],\n",
      "        [0, 0]], dtype=torch.int32)\n",
      "\n",
      "Tensor from t2 with random values:\n",
      "tensor([[0.0267, 0.3853],\n",
      "        [0.8086, 0.7023]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# from an existing tensor\n",
    "t3 = torch.ones_like(t2)\n",
    "t4 = torch.zeros_like(t2)\n",
    "t5 = torch.rand_like(t2, dtype=torch.float)\n",
    "\n",
    "print(f\"Tensor from t2 with all ones:\\n{t3}\\n\")\n",
    "print(f\"Tensor from t2 with all zeros:\\n{t4}\\n\")\n",
    "print(f\"Tensor from t2 with random values:\\n{t5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52e5d93",
   "metadata": {},
   "source": [
    "Another common way to initialize a tensor is by providing the shape of the tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "11dba7e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor of all ones with dimensions 2x2:\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "\n",
      "Tensor of all zeros with dimensions 2x3:\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "t6 = torch.ones(2,2)\n",
    "t7 = torch.zeros(2,3)\n",
    "\n",
    "print(f\"Tensor of all ones with dimensions 2x2:\\n{t6}\\n\")\n",
    "print(f\"Tensor of all zeros with dimensions 2x3:\\n{t7}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2776e6",
   "metadata": {},
   "source": [
    "Although there are many more ways to initialize a tensor, in order to keep this tutorial brief we won't introduce any more here. If you are curious, you can read the following Tensor guide: [Tensor Creation](https://docs.pytorch.org/docs/stable/torch.html#creation-ops)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec24e7c4",
   "metadata": {},
   "source": [
    "### Attributes\n",
    "\n",
    "Tensors have built in attributes that quickly provide machine learning engineers useful information about the tensors they constructed. Tensor attributes can be accessed with the notation `tensor.attribute`. There are over 1000 tensor attributes that you can read about [here](https://docs.pytorch.org/docs/stable/torch.html), but in this tutorial we will cover the following:\n",
    "- `dtype`\n",
    "- `shape`\n",
    "- `device`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041a777f",
   "metadata": {},
   "source": [
    "`dtype` returns the torch datatype of a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b67dc55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 1., 1.],\n",
      "         [1., 1., 1.],\n",
      "         [1., 1., 1.],\n",
      "         [1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.],\n",
      "         [1., 1., 1.],\n",
      "         [1., 1., 1.],\n",
      "         [1., 1., 1.]]])\n",
      "\n",
      "Datatype: torch.float32\n"
     ]
    }
   ],
   "source": [
    "t = torch.ones(2,4,3)\n",
    "print(t)\n",
    "print(f\"\\nDatatype: {t.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bbfbc0",
   "metadata": {},
   "source": [
    "`shape` returns the dimensions of the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a52c04fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "print(t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30d5896",
   "metadata": {},
   "source": [
    "`device` returns the location a tensor is stored.\n",
    "\n",
    "By default, tensors are stored on the CPU. However, PyTorch provides the ability to store tensors on an accelerator, such as a GPU, to greatly improve performance. Accelerators are designed to optimize operations performed on tensors and can be 10-100x faster than when performed on the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "65e38cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(t.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25218f68",
   "metadata": {},
   "source": [
    "\n",
    "To check if you have an accelerator available, you can use the function `torch.accelerator.is_available()` which returns True or False. If an accelerator is availble, you can determine the devices name using `torch.accelerator.current_accelerator()`, and then move the tensor onto the accelerator using the function `to(accelerator_device_name)`.\n",
    "\n",
    "In this tutorial we will not assume you have an accelerator available to use, but the below commented out code shows how to use a tensor on an accelerator if the option is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4feb7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accelerator is available: {torch.accelerator.is_available()}\")\n",
    "\n",
    "print(f\"Device of available accelerator: {torch.accelerator.current_accelerator()}\")\n",
    "\n",
    "# Move an existing tensor onto an accelerator\n",
    "# t = t.to(torch.accelerator.current_accelerator())\n",
    "\n",
    "# Initialize a new tensor onto an accelerator using the optional device argument\n",
    "# t1 = torch.tensor([1,2,3], device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d67578",
   "metadata": {},
   "source": [
    "### Operations\n",
    "\n",
    "- indexing and slicing (say numpy like and don't go too in-depth)\n",
    "- multiplying math (brief mention)\n",
    "- item\n",
    "- highlight softmax and argmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44649702",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cedfd2f7",
   "metadata": {},
   "source": [
    "## Handling Data\n",
    "\n",
    "The first step in creating a neural network is loading the data. Thankfully, PyTorch provides many tools to make loading and iterating through data simple!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199228f0",
   "metadata": {},
   "source": [
    "### Datasets\n",
    "\n",
    "Torchvision is library often used alongside PyTorch to support computer vision tasks. It also contains built-in datasets that can be easily loaded in and used to train neural networks in PyTorch, including the MNIST dataset that we will be training a model on!\n",
    "\n",
    "To load in the MSNIST dataset, we must first import the datasets submodule from torchvision. We also import ToTensor from the transforms submodule which will be used to transform the handwritten digit images into PyTorch Tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3397ea6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d89283",
   "metadata": {},
   "source": [
    "Now, we can use the following code to load in MNIST dataset. PROBABLY WANT TO REORDER SOME OF THE MARKDOWN / MOVE SOME OF IT INTO COMMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9a9a2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [01:11<00:00, 139kB/s] \n",
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.19MB/s]\n",
      "100%|██████████| 1.65M/1.65M [00:03<00:00, 491kB/s]\n",
      "100%|██████████| 4.54k/4.54k [00:00<?, ?B/s]\n"
     ]
    }
   ],
   "source": [
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2bf47b",
   "metadata": {},
   "source": [
    "We load training data and testing data separately, that way we can train the model using the training data and then test it on never before seen data, to ensure the model is indeed learning how to classify digits and not just memorizing the training dataset. \n",
    "\n",
    "`training_data` is a set of 60,000 handwritten digit images with their corresponding labels (0-9)\n",
    "\n",
    "`test_data` is a set of 10,000 handwritten digit images with their corresponding labels (0-9) DOUBLE CHECK THIS IS TRUE\n",
    "\n",
    "Don't worry too much about the parameters for loading in data now, but briefly:\n",
    "- `root` is the path where the train/test data is stored\n",
    "- `train` specifies training or test dataset\n",
    "- `download` if true, dowloads the data from the internet if it's not available at `root`.\n",
    "- `transform` specify the feature and label transformations\n",
    "\n",
    "We can look at the first image in the training data set using the following code: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64d5a7a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img, label = training_data[0]\n",
    "plt.imshow(img.squeeze(), cmap=\"gray\") \n",
    "plt.title(f\"Label: {label}\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d47a091",
   "metadata": {},
   "source": [
    "### DataLoader\n",
    "\n",
    "When training and testing the model, we will repeatedly need to iterate through our datasets. In order to optimize the process, we would like to handle batching, shuffling the data, and loading it in parrallel. Thankfully, PyTorch provides DataLoaders to make this process easy.\n",
    "\n",
    "The following code creates two DataLoaders, one for each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03785c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    training_data,\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data,\n",
    "    batch_size=4,\n",
    "    shuffle=False,\n",
    "    num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe0353c",
   "metadata": {},
   "source": [
    "Again don't worry too much about the parameters, but briefly: \n",
    "- `batch_size` is how many samples are loaded in each iteration\n",
    "- `shuffle` is whether to randomly suffle the data\n",
    "- `num_workers` is how many subprocesses to use for data loading (parrallelization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3757f52f",
   "metadata": {},
   "source": [
    "After creating a DataLoader, you can get a batch of samples by calling `next(iter(dataloader_name))`. MAYBE REWRITE THIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5826c903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get one batch of training samples\n",
    "train_features, train_labels = next(iter(train_loader))\n",
    "\n",
    "# Plot all 4 images\n",
    "fig, axes = plt.subplots(2, 2, figsize=(6, 6))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    img = train_features[i].squeeze() \n",
    "    label = train_labels[i].item()\n",
    "    ax.imshow(img, cmap=\"gray\")\n",
    "    ax.set_title(f\"Label: {label}\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdc5171",
   "metadata": {},
   "source": [
    "## Constructing a Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66116c28",
   "metadata": {},
   "source": [
    "### Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14ac883",
   "metadata": {},
   "source": [
    "### Activation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd07ac35",
   "metadata": {},
   "source": [
    "### Init and Forward Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79633c0e",
   "metadata": {},
   "source": [
    "## Loss Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Using a Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and Export a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016ef1d4",
   "metadata": {},
   "source": [
    "## Conclusion and Further Readings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
